# TROPOMI_EXTRACTS
Scripts to gather Tropomi Extracts for airsheds

## Directory Tree
├── data <br>
│   ├── HCHO_csvs <br>
│   ├── HCHO_tifs <br>
│   ├── NO2_csvs <br>
│   ├── NO2_tifs <br>
│   ├── SO2_csvs <br>
│   ├── SO2_tifs <br>
│   ├── O3_csvs <br>
│   ├── O3_tifs <br>
│   ├── gridextents_shponly : Shapefiles of 104 airsheds<br>
│   ├── timeseries : Timeseries CSV for each airshed<>pollutant<br>

All csvs/tifs are updated between 2019-01-01 to 2023-12-31

├── scripts <br>
│   ├── tropomiextract.py <br>
│   ├── check.py <br>
│   ├── dataprocess.py <br>
│   ├── plot.py <br>

├── plots <br>
Plots generated by `plot.py`

## How to run the script?
Run scripts from the project directory.

1. `tropomiextract.py` code helps in extracting TROPOMI dataset for a given airshed. It downloads a tif image and a csv for a 15 day average period. `HCHO`, `NO2`, `SO2`, `O3` pollutants are covered in this code. There are only two user inputs needed (inside code) to execute this script:
    a. `pollutant_to_extract` - one of these `HCHO`, `NO2`, `SO2`, `O3` 
    b. `year_to_extract` - 2019 onwards.

Example usage: `python scripts/tropomiextract.py NO2 2023`

2. Ideally, you would have 24 csvs per year. But due to connectivity issues, the above code would skip producing a few csvs. Use `check.py` to see which airsheds have incomplete extracts.

3. `dataprocess.py`: Once all csvs are downloaded, Run this code to create a single timeseries csv for each airshed. These csvs are stored in timeseries csv.

Example usage: `python scripts/dataprocess.py NO2`

4. `plot.py`: If you want to see the timeseries plot based on the timeseries CSVs produced above.
Example usage: `python scripts/plot.py NO2 hyderabad`

